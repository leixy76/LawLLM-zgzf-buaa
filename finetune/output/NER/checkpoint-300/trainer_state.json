{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.529333921482135,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0176444640494045,
      "grad_norm": 2.875,
      "learning_rate": 9.91166077738516e-05,
      "loss": 0.4045,
      "step": 10
    },
    {
      "epoch": 0.035288928098809,
      "grad_norm": 2.03125,
      "learning_rate": 9.823321554770319e-05,
      "loss": 0.1337,
      "step": 20
    },
    {
      "epoch": 0.0529333921482135,
      "grad_norm": 2.34375,
      "learning_rate": 9.734982332155478e-05,
      "loss": 0.1103,
      "step": 30
    },
    {
      "epoch": 0.070577856197618,
      "grad_norm": 2.53125,
      "learning_rate": 9.646643109540636e-05,
      "loss": 0.0896,
      "step": 40
    },
    {
      "epoch": 0.08822232024702249,
      "grad_norm": 1.625,
      "learning_rate": 9.558303886925796e-05,
      "loss": 0.1079,
      "step": 50
    },
    {
      "epoch": 0.105866784296427,
      "grad_norm": 1.1328125,
      "learning_rate": 9.469964664310954e-05,
      "loss": 0.11,
      "step": 60
    },
    {
      "epoch": 0.12351124834583149,
      "grad_norm": 1.7578125,
      "learning_rate": 9.381625441696114e-05,
      "loss": 0.1967,
      "step": 70
    },
    {
      "epoch": 0.141155712395236,
      "grad_norm": 1.6875,
      "learning_rate": 9.293286219081273e-05,
      "loss": 0.0657,
      "step": 80
    },
    {
      "epoch": 0.1588001764446405,
      "grad_norm": 1.9921875,
      "learning_rate": 9.204946996466431e-05,
      "loss": 0.0557,
      "step": 90
    },
    {
      "epoch": 0.17644464049404499,
      "grad_norm": 2.3125,
      "learning_rate": 9.116607773851592e-05,
      "loss": 0.0656,
      "step": 100
    },
    {
      "epoch": 0.1940891045434495,
      "grad_norm": 14.0625,
      "learning_rate": 9.02826855123675e-05,
      "loss": 0.2749,
      "step": 110
    },
    {
      "epoch": 0.211733568592854,
      "grad_norm": 2.546875,
      "learning_rate": 8.939929328621908e-05,
      "loss": 0.0577,
      "step": 120
    },
    {
      "epoch": 0.22937803264225848,
      "grad_norm": 1.546875,
      "learning_rate": 8.851590106007068e-05,
      "loss": 0.0691,
      "step": 130
    },
    {
      "epoch": 0.24702249669166298,
      "grad_norm": 1.0859375,
      "learning_rate": 8.763250883392227e-05,
      "loss": 0.0851,
      "step": 140
    },
    {
      "epoch": 0.2646669607410675,
      "grad_norm": 2.328125,
      "learning_rate": 8.674911660777384e-05,
      "loss": 0.0861,
      "step": 150
    },
    {
      "epoch": 0.282311424790472,
      "grad_norm": 1.34375,
      "learning_rate": 8.586572438162545e-05,
      "loss": 0.0434,
      "step": 160
    },
    {
      "epoch": 0.2999558888398765,
      "grad_norm": 1.1328125,
      "learning_rate": 8.498233215547704e-05,
      "loss": 0.0399,
      "step": 170
    },
    {
      "epoch": 0.317600352889281,
      "grad_norm": 0.1923828125,
      "learning_rate": 8.409893992932862e-05,
      "loss": 0.0436,
      "step": 180
    },
    {
      "epoch": 0.33524481693868546,
      "grad_norm": 2.671875,
      "learning_rate": 8.321554770318022e-05,
      "loss": 0.0444,
      "step": 190
    },
    {
      "epoch": 0.35288928098808997,
      "grad_norm": 0.578125,
      "learning_rate": 8.23321554770318e-05,
      "loss": 0.0553,
      "step": 200
    },
    {
      "epoch": 0.3705337450374945,
      "grad_norm": 2.578125,
      "learning_rate": 8.14487632508834e-05,
      "loss": 0.0409,
      "step": 210
    },
    {
      "epoch": 0.388178209086899,
      "grad_norm": 1.375,
      "learning_rate": 8.056537102473498e-05,
      "loss": 0.0324,
      "step": 220
    },
    {
      "epoch": 0.4058226731363035,
      "grad_norm": 1.5,
      "learning_rate": 7.968197879858657e-05,
      "loss": 0.0372,
      "step": 230
    },
    {
      "epoch": 0.423467137185708,
      "grad_norm": 3.140625,
      "learning_rate": 7.879858657243818e-05,
      "loss": 0.1883,
      "step": 240
    },
    {
      "epoch": 0.4411116012351125,
      "grad_norm": 0.81640625,
      "learning_rate": 7.791519434628976e-05,
      "loss": 0.0409,
      "step": 250
    },
    {
      "epoch": 0.45875606528451696,
      "grad_norm": 1.3828125,
      "learning_rate": 7.703180212014135e-05,
      "loss": 0.0407,
      "step": 260
    },
    {
      "epoch": 0.47640052933392146,
      "grad_norm": 1.296875,
      "learning_rate": 7.614840989399294e-05,
      "loss": 0.0482,
      "step": 270
    },
    {
      "epoch": 0.49404499338332597,
      "grad_norm": 1.046875,
      "learning_rate": 7.526501766784453e-05,
      "loss": 0.0612,
      "step": 280
    },
    {
      "epoch": 0.5116894574327305,
      "grad_norm": 1.046875,
      "learning_rate": 7.43816254416961e-05,
      "loss": 0.0472,
      "step": 290
    },
    {
      "epoch": 0.529333921482135,
      "grad_norm": 0.482421875,
      "learning_rate": 7.349823321554771e-05,
      "loss": 0.0404,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 1132,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.434821237342208e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
