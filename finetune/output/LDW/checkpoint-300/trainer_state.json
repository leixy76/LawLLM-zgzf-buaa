{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4563106796116505,
  "eval_steps": 500,
  "global_step": 300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04854368932038835,
      "grad_norm": 3.84375,
      "learning_rate": 9.757281553398059e-05,
      "loss": 1.4944,
      "step": 10
    },
    {
      "epoch": 0.0970873786407767,
      "grad_norm": 3.765625,
      "learning_rate": 9.514563106796118e-05,
      "loss": 1.367,
      "step": 20
    },
    {
      "epoch": 0.14563106796116504,
      "grad_norm": 4.5,
      "learning_rate": 9.271844660194175e-05,
      "loss": 1.1858,
      "step": 30
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 3.265625,
      "learning_rate": 9.029126213592234e-05,
      "loss": 1.1069,
      "step": 40
    },
    {
      "epoch": 0.24271844660194175,
      "grad_norm": 3.765625,
      "learning_rate": 8.786407766990292e-05,
      "loss": 1.2034,
      "step": 50
    },
    {
      "epoch": 0.2912621359223301,
      "grad_norm": 3.1875,
      "learning_rate": 8.54368932038835e-05,
      "loss": 1.2086,
      "step": 60
    },
    {
      "epoch": 0.33980582524271846,
      "grad_norm": 5.4375,
      "learning_rate": 8.300970873786408e-05,
      "loss": 1.2098,
      "step": 70
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 3.46875,
      "learning_rate": 8.058252427184466e-05,
      "loss": 1.0511,
      "step": 80
    },
    {
      "epoch": 0.4368932038834951,
      "grad_norm": 3.546875,
      "learning_rate": 7.815533980582524e-05,
      "loss": 1.2167,
      "step": 90
    },
    {
      "epoch": 0.4854368932038835,
      "grad_norm": 3.59375,
      "learning_rate": 7.572815533980583e-05,
      "loss": 1.0876,
      "step": 100
    },
    {
      "epoch": 0.5339805825242718,
      "grad_norm": 2.984375,
      "learning_rate": 7.330097087378641e-05,
      "loss": 1.1352,
      "step": 110
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 3.578125,
      "learning_rate": 7.0873786407767e-05,
      "loss": 1.0882,
      "step": 120
    },
    {
      "epoch": 0.6310679611650486,
      "grad_norm": 4.84375,
      "learning_rate": 6.844660194174757e-05,
      "loss": 1.0879,
      "step": 130
    },
    {
      "epoch": 0.6796116504854369,
      "grad_norm": 3.0625,
      "learning_rate": 6.601941747572816e-05,
      "loss": 1.0722,
      "step": 140
    },
    {
      "epoch": 0.7281553398058253,
      "grad_norm": 3.265625,
      "learning_rate": 6.359223300970875e-05,
      "loss": 1.0506,
      "step": 150
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 3.890625,
      "learning_rate": 6.116504854368932e-05,
      "loss": 1.0179,
      "step": 160
    },
    {
      "epoch": 0.8252427184466019,
      "grad_norm": 3.6875,
      "learning_rate": 5.87378640776699e-05,
      "loss": 1.095,
      "step": 170
    },
    {
      "epoch": 0.8737864077669902,
      "grad_norm": 3.578125,
      "learning_rate": 5.6310679611650486e-05,
      "loss": 1.0539,
      "step": 180
    },
    {
      "epoch": 0.9223300970873787,
      "grad_norm": 4.1875,
      "learning_rate": 5.3883495145631065e-05,
      "loss": 1.0039,
      "step": 190
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 3.15625,
      "learning_rate": 5.145631067961165e-05,
      "loss": 1.0864,
      "step": 200
    },
    {
      "epoch": 1.0194174757281553,
      "grad_norm": 2.6875,
      "learning_rate": 4.902912621359224e-05,
      "loss": 0.9045,
      "step": 210
    },
    {
      "epoch": 1.0679611650485437,
      "grad_norm": 3.546875,
      "learning_rate": 4.660194174757282e-05,
      "loss": 0.8178,
      "step": 220
    },
    {
      "epoch": 1.116504854368932,
      "grad_norm": 3.203125,
      "learning_rate": 4.4174757281553404e-05,
      "loss": 0.935,
      "step": 230
    },
    {
      "epoch": 1.1650485436893203,
      "grad_norm": 3.421875,
      "learning_rate": 4.1747572815533984e-05,
      "loss": 0.8924,
      "step": 240
    },
    {
      "epoch": 1.2135922330097086,
      "grad_norm": 3.921875,
      "learning_rate": 3.9320388349514564e-05,
      "loss": 0.8352,
      "step": 250
    },
    {
      "epoch": 1.262135922330097,
      "grad_norm": 3.265625,
      "learning_rate": 3.689320388349515e-05,
      "loss": 0.8262,
      "step": 260
    },
    {
      "epoch": 1.3106796116504853,
      "grad_norm": 3.5625,
      "learning_rate": 3.446601941747573e-05,
      "loss": 0.7077,
      "step": 270
    },
    {
      "epoch": 1.3592233009708738,
      "grad_norm": 4.59375,
      "learning_rate": 3.2038834951456316e-05,
      "loss": 0.8377,
      "step": 280
    },
    {
      "epoch": 1.4077669902912622,
      "grad_norm": 4.09375,
      "learning_rate": 2.9611650485436892e-05,
      "loss": 0.8341,
      "step": 290
    },
    {
      "epoch": 1.4563106796116505,
      "grad_norm": 3.6875,
      "learning_rate": 2.7184466019417475e-05,
      "loss": 0.7702,
      "step": 300
    }
  ],
  "logging_steps": 10,
  "max_steps": 412,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.1322699751817216e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
